version: "3"

services:
  namenode:
    image: ramilu90/hadoop-namenode
    container_name: namenode
    platform: linux/amd64
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    mem_limit: 1g  # Allocate 1 GB for NameNode
    env_file:
      - ./hadoop.env

  datanode:
    image: ramilu90/hadoop-datanode
    container_name: datanode
    platform: linux/amd64
    restart: always
    ports:
      - "9864:9864"
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    mem_limit: 1g  # Allocate 1 GB for DataNode
    env_file:
      - ./hadoop.env

  resourcemanager:
    image: ramilu90/hadoop-datanode
    container_name: resourcemanager
    platform: linux/amd64
    restart: always
    environment:
      - SERVICE_PRECONDITION=namenode:9000 namenode:9870 datanode:9864
    mem_limit: 512m  # Allocate 512 MB for ResourceManager
    env_file:
      - ./hadoop.env

  nodemanager:
    image: ramilu90/hadoop-datanode
    container_name: nodemanager
    platform: linux/amd64
    restart: always
    environment:
      - SERVICE_PRECONDITION=namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088
    mem_limit: 512m  # Allocate 512 MB for NodeManager
    env_file:
      - ./hadoop.env # Allocate 512 MB for Spark Worker
